{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6067,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6068,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6069,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(file_name='./train.csv'):\n",
    "    train_df = pd.read_csv(file_name)\n",
    "    train_df.drop(train_df.columns[0],axis=1,inplace=True)\n",
    "    train_npa = train_df.to_numpy()\n",
    "    \n",
    "    train_data = []\n",
    "    max_item_id = 0\n",
    "    max_user_id = train_npa.shape[0]\n",
    "\n",
    "    for i, docs in enumerate(train_npa):\n",
    "        tmp_arr = np.array(list(map(int, list(docs)[0].split())))\n",
    "        tmp_max = np.max(tmp_arr)\n",
    "        if tmp_max > max_item_id:\n",
    "            max_item_id = tmp_max\n",
    "        train_data.append(tmp_arr)\n",
    "\n",
    "    train_data = np.array(train_data, dtype=object)\n",
    "\n",
    "    return train_data, max_item_id, max_user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6070,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_rating_matrix(train_data, max_item_id, max_user_id):\n",
    "    R = np.zeros((max_item_id, max_user_id))\n",
    "    \n",
    "    for i in range(max_item_id):\n",
    "        for j in range(max_user_id):\n",
    "            if i in train_data[j]:\n",
    "                # user j interacted with item i\n",
    "                R[i][j] = 1\n",
    "    \n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6071,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bce_loss(data, i, j):\n",
    "    hor_sum = np.sum(data, axis=1)\n",
    "    vert_sum = np.sum(data, axis=0)\n",
    "    \n",
    "    return -(data[i, j]*np.ln(hor_sum[i]) + (1-data[i, j])*np.ln(1-vert_sum[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6072,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gradient_descent(start, learn_rate=0.01, n_iter=50, tolerance=1e-06):\n",
    "#     vector = start\n",
    "#     for _ in range(n_iter):\n",
    "# #         diff = -learn_rate * np.gradient(vector)\n",
    "#         if np.all(np.abs(diff) <= tolerance):\n",
    "#             break\n",
    "#         vector += diff\n",
    "#     return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6073,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_occurrences(row):\n",
    "    return len([x for x in row if x == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6074,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gradient_descent(R, P, Q, max_iter=1, learn_rate=0.01, n_iter=50, tolerance=1e-06, lamb1=0.001, lamb2=0.001):\n",
    "#     for iters in range(max_iter):\n",
    "#         print(\"iteration: {}\".format(iters))\n",
    "#         for x in range(R.shape[1]):\n",
    "#             for i in range(R.shape[0]):\n",
    "# #                 o = count_occurrences()\n",
    "# #                 eps = R[i, x] - (np.dot(Q[i], P[x]))\n",
    "# #                 eps = R[i, x] - (np.log(sigmoid(Q[i])) + np.log(sigmoid(P[x])))\n",
    "#                 p = sigmoid(np.dot(Q[i], P[x]))\n",
    "# #                 print(p)\n",
    "#                 if math.isnan(p):\n",
    "#                     print(\"({}, {}) --- Q[i]: {}, P[x]: {}\".format(x, i, Q[i], P[x]))\n",
    "#                 if p == 0:\n",
    "#                     p = 0.01\n",
    "#                 if (1-p) <= 0:\n",
    "#                     p = 0.99\n",
    "#                 y = R[i, x]\n",
    "# #                 print(p)\n",
    "                \n",
    "#                 try:\n",
    "#                     eps = -(np.sum(y*np.log(p) + (1-y)*(np.log(1-p))))\n",
    "# #                     print(eps)\n",
    "#                     if math.isinf(eps) or math.isnan(eps):\n",
    "#                         print(\"eps is wrong --- y: {}, p: {}\".format(y, p))\n",
    "#                 except:\n",
    "#                     print(\"p: {}\".format(p))\n",
    "#                     print(\"y: {}\".format(y))\n",
    "# #                 eps = -(R[i, x]*np.log(pred) + (1-R[i, x])*np.log((1-pred)))\n",
    "\n",
    "#                 if (y-p) <= 0:\n",
    "#                     eps = -eps\n",
    "#                 Q[i] = Q[i] + learn_rate*(eps*P[x]-lamb2*Q[i])\n",
    "# #                 print(learn_rate*(eps*Q[i]-lamb1*P[x]))\n",
    "#                 P[x] = P[x] + learn_rate*(eps*Q[i]-lamb1*P[x])\n",
    "    \n",
    "#     return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6075,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(R, P, Q, max_iter=15, learn_rate=0.001, lamb1=0.001, lamb2=0.001):\n",
    "    for iters in range(max_iter):\n",
    "        print(\"iteration: {}\".format(iters))\n",
    "        \n",
    "        r = np.random.randint(0, Q.shape[0])\n",
    "        for i in range(P.shape[0]):\n",
    "            y = R[r, i]\n",
    "            p = np.dot(Q[r], P[i])\n",
    "            eps = (-y/p)+((1-y)/(1-p))\n",
    "            eps = np.sign(p)*eps\n",
    "\n",
    "            Q[r] = Q[r] + learn_rate*(-eps*P[i]-lamb2*Q[r])\n",
    "            P[i] = P[i] + learn_rate*(-eps*Q[r]-lamb1*P[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "        r = np.random.randint(0, P.shape[0])\n",
    "        for i in range(Q.shape[0]):\n",
    "#             eps = R[i, r] - (np.dot(Q[i], P[r]))\n",
    "            y = R[i, r]\n",
    "            p = np.dot(Q[i], P[r])\n",
    "            eps = (-y/p)+((1-y)/(1-p))\n",
    "            \n",
    "            eps = np.sign(p)*eps\n",
    "    \n",
    "            Q[i] = Q[i] + learn_rate*(-eps*P[r]-lamb2*Q[i])\n",
    "            P[r] = P[r] + learn_rate*(-eps*Q[i]-lamb1*P[r])\n",
    "            \n",
    "#             print(\"before: y: {} p: {}, after: {}\".format(y, p, np.dot(Q[i], P[r])))\n",
    "    \n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6076,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def gradient_descent(R, P, Q, max_iter=1, learn_rate=0.1, tolerance=1e-06, lamb1=0.01, lamb2=0.01):\n",
    "#     for iters in range(max_iter):\n",
    "#         for x in range(R.shape[1]):\n",
    "#             for i in range(R.shape[0]):\n",
    "        \n",
    "#                 y = R[i, x]\n",
    "#                 p = np.dot(Q[i], P[x])\n",
    "# #                 print(\"y: {}, p: {}\".format(y, p))\n",
    "# #                 if p > 1:\n",
    "# #                     print(p)\n",
    "# #                 if p >= 1:\n",
    "# #                     p = 0.99\n",
    "# #                 if p < 0:\n",
    "# #                     p = 0.99\n",
    "\n",
    "#                 eps = (-y/p)+((1-y)/(1-p))\n",
    "# #                 eps = np.sign(eps)\n",
    "# #                 print(eps)\n",
    "#                 eps = np.sign(p)*eps\n",
    "#                 Q[i] = Q[i] + learn_rate*(-eps*P[x]-lamb2*Q[i])\n",
    "#                 P[x] = P[x] + learn_rate*(-eps*Q[i]-lamb1*P[x])\n",
    "\n",
    "# #                 print(\"before: y: {} p: {}, after: {}\".format(y, p, np.dot(Q[i], P[x])))\n",
    "                \n",
    "#     return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6077,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_most_relevant(mat, n=50):\n",
    "    res = []\n",
    "    \n",
    "    for i in range(mat.shape[0]):\n",
    "        d = dict(enumerate(mat[i]))\n",
    "        sl = sorted(d.items(), key=lambda item: item[1], reverse=True)\n",
    "        res.append(sl[:n])\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6078,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_result_csv(rel_items):        \n",
    "#     res = pd.DataFrame.from_dict(rel_items, orient='index', columns=['ItemId'])\n",
    "    for k, v in rel_items.items():\n",
    "        rel_items[k] = ' '.join(str(x) for x in v)\n",
    "        \n",
    "    res = pd.DataFrame([{'ItemId': v} for v in rel_items.values()], index=rel_items.keys())\n",
    "    res.index.name = 'UserId'\n",
    "    \n",
    "    res.to_csv('./submission.csv')  \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6079,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _sample(self, n_users, n_items, indices, indptr):\n",
    "        \"\"\"sample batches of random triplets u, i, j\"\"\"\n",
    "        sampled_pos_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "        sampled_neg_items = np.zeros(self.batch_size, dtype = np.int)\n",
    "        sampled_users = np.random.choice(\n",
    "            n_users, size = self.batch_size, replace = False)\n",
    "\n",
    "        for idx, user in enumerate(sampled_users):\n",
    "            pos_items = indices[indptr[user]:indptr[user + 1]]\n",
    "            pos_item = np.random.choice(pos_items)\n",
    "            neg_item = np.random.choice(n_items)\n",
    "            while neg_item in pos_items:\n",
    "                neg_item = np.random.choice(n_items)\n",
    "\n",
    "            sampled_pos_items[idx] = pos_item\n",
    "            sampled_neg_items[idx] = neg_item\n",
    "\n",
    "        return sampled_users, sampled_pos_items, sampled_neg_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6080,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 3, 5], dtype=int64)"
      ]
     },
     "execution_count": 6080,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = np.array([1, 0, 0, 1, 0, 1])\n",
    "itemindex = np.where(test == 1)[0]\n",
    "itemindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6081,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_sgd(R, max_iter=10, learn_rate=0.001, lamb=0.001):\n",
    "#     Q = np.random.uniform(0, 1, size=(R.shape[1], 16))\n",
    "#     P = np.random.uniform(0, 1, size=(R.shape[0], 16))\n",
    "\n",
    "    n_users = R.shape[1]\n",
    "    n_items = R.shape[0]\n",
    "    batch_size = 100\n",
    "    n_factors = 20\n",
    "\n",
    "    batch_iters = n_users // batch_size\n",
    "\n",
    "    rstate = np.random.RandomState(1234)\n",
    "    Q = rstate.normal(size = (R.shape[1], n_factors))\n",
    "    P = rstate.normal(size = (R.shape[0], n_factors))\n",
    "    \n",
    "    for it in range(max_iter):\n",
    "        for _ in range(batch_iters):\n",
    "            sampled_pos_items = np.zeros(batch_size, dtype = np.int)\n",
    "            sampled_neg_items = np.zeros(batch_size, dtype = np.int)\n",
    "            sampled_users = np.random.choice(n_users, size = batch_size, replace = False)\n",
    "            \n",
    "            for idx, user in enumerate(sampled_users):\n",
    "                pos_items = np.where(np.array(R[:, user]) == 1)[0]\n",
    "                pos_item = np.random.choice(pos_items)\n",
    "                \n",
    "                neg_items = np.where(np.array(R[:, user]) == 0)[0]\n",
    "                neg_item = np.random.choice(neg_items)\n",
    "#                 neg_item = np.random.choice(n_items)\n",
    "#                 while neg_item in pos_items:\n",
    "#                     neg_item = np.random.choice(n_items)\n",
    "\n",
    "                sampled_pos_items[idx] = pos_item\n",
    "                sampled_neg_items[idx] = neg_item\n",
    "#             print(sampled_pos_items)\n",
    "#             print(sampled_neg_items)\n",
    "#             u = np.random.randint(0, R.shape[1])\n",
    "#             i = np.random.randint(0, R.shape[0])\n",
    "#             j = np.random.randint(0, R.shape[0])\n",
    "            u = sampled_users\n",
    "            i = sampled_pos_items\n",
    "            j = sampled_neg_items\n",
    "            \n",
    "            xuij = np.sum(Q[u] * (P[i] - P[j]), axis = 1)\n",
    "\n",
    "            sig = np.exp(-xuij) / (1.0 + np.exp(-xuij))\n",
    "            sig_t = np.tile(sig, (n_factors, 1)).T\n",
    "\n",
    "            grad_u = sig_t * (P[j] - P[i]) + lamb * Q[u]\n",
    "            grad_i = sig_t * -Q[u] + lamb * P[i]\n",
    "            grad_j = sig_t * Q[u] + lamb * P[j]\n",
    "            Q[u] -= learn_rate * grad_u\n",
    "            P[i] -= learn_rate * grad_i\n",
    "            P[j] -= learn_rate * grad_j\n",
    "    \n",
    "    return P, Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6082,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def partial_BPR(x_uij, partial_x):\n",
    "#     exp_x = np.exp(-x_uij)\n",
    "#     return exp_x / (1 + exp_x) * partial_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6083,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bpr_sgd(R, iteration=100, lr=0.01, rr=0.01, k=16):\n",
    "#     W = np.random.uniform(0, 1, size=(R.shape[1], k))\n",
    "#     H = np.random.uniform(0, 1, size=(R.shape[0], k))\n",
    "    \n",
    "#     for itr in range(iteration):\n",
    "# #         u, i, j = ds[np.random.randint(len(ds))]\n",
    "#         u = np.random.randint(0, R.shape[1])\n",
    "#         i = np.random.randint(0, R.shape[0])\n",
    "#         j = np.random.randint(0, R.shape[0])\n",
    "            \n",
    "# #         x_uij = predict_diff(u, i, j)\n",
    "#         x_uij = np.sum(W[u] * (H[i]-H[j]))\n",
    "\n",
    "#         for f in range(k):\n",
    "#             W[u][f] -= lr * (partial_BPR(x_uij, H[i][f] - H[j][f]) + rr * W[u][f])\n",
    "#             H[i][f] -= lr * (partial_BPR(x_uij, W[u][f]) + rr * H[i][f])\n",
    "#             H[j][f] -= lr * (partial_BPR(x_uij, -W[u][f]) + rr * H[f][f])\n",
    "        \n",
    "# #         if itr % 10000 == 0:\n",
    "# #             print(W[18])\n",
    "# #             print(H[0])\n",
    "            \n",
    "#     return W, H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6084,
   "metadata": {},
   "outputs": [],
   "source": [
    "#         # Q (W)\n",
    "#         d = (P[i]-P[j])\n",
    "#         Q[u] = Q[u] + learn_rate*(((np.exp(-xuij))/(1+np.exp(-xuij))) * d + lamb*Q[u])\n",
    "        \n",
    "#         # Pi (H)\n",
    "#         d = -Q[u]\n",
    "#         P[i] = P[i] + learn_rate*(((np.exp(-xuij))/(1+np.exp(-xuij))) * d + lamb*P[i])\n",
    "        \n",
    "#         # Pj (H)\n",
    "#         d = Q[u]\n",
    "#         P[j] = P[j] + learn_rate*(((np.exp(-xuij))/(1+np.exp(-xuij))) * d + lamb*P[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6085,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, max_item_id, max_user_id = prepare_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6086,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = create_rating_matrix(train_data, max_item_id, max_user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6087,
   "metadata": {},
   "outputs": [],
   "source": [
    "M, N = R.shape[0], R.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6088,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u, s, vh = np.linalg.svd(R, )\n",
    "\n",
    "# # P = u\n",
    "# # Q = np.matmul(s, vh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6089,
   "metadata": {},
   "outputs": [],
   "source": [
    "# P = np.matmul(u, s)\n",
    "# Q = vh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6090,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_Q = np.random.uniform(0, 1, size=(M, 2))\n",
    "# initial_P = np.random.uniform(0, 1, size=(N, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6091,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_Q = np.random.uniform(0, 1, size=(M, 2))\n",
    "# initial_P = np.random.uniform(0, 1, size=(N, 2))\n",
    "# P, Q = gradient_descent(R, initial_P, initial_Q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6092,
   "metadata": {},
   "outputs": [],
   "source": [
    "P, Q = bpr_sgd(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6093,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = np.matmul(Q, np.transpose(P))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6094,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ids = np.argpartition(M, -50)[-50:]\n",
    "# best_ids = np.argsort(M[ids])[::-1]\n",
    "# best = ids[best_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6095,
   "metadata": {},
   "outputs": [],
   "source": [
    "relevant_items = get_most_relevant(M)\n",
    "rel_items = [[x[0] for x in l] for l in relevant_items]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6096,
   "metadata": {},
   "outputs": [],
   "source": [
    "rel_items_dict = dict(enumerate(rel_items))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6097,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_result_csv(rel_items_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6098,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_overlap():\n",
    "    tdf = pd.read_csv('train.csv')\n",
    "    sdf = pd.read_csv('submission.csv')\n",
    "    \n",
    "    return tdf, sdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6099,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf, sdf = calculate_overlap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_npa = tdf.to_numpy()\n",
    "sub_npa = sdf.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6101,
   "metadata": {},
   "outputs": [],
   "source": [
    "ta = []\n",
    "for idx, r in enumerate(train_npa):\n",
    "    ta.append(np.array(train_npa[idx][1].split(' '), dtype=np.int))\n",
    "ta = np.array(ta, dtype=object)\n",
    "\n",
    "sa = []\n",
    "for idx, r in enumerate(sub_npa):\n",
    "    sa.append(np.array(sub_npa[idx][1].split(' '), dtype=np.int))\n",
    "sa = np.array(sa, dtype=object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6102,
   "metadata": {},
   "outputs": [],
   "source": [
    "isec = []\n",
    "for i in range(len(ta)):\n",
    "    isec.append(np.intersect1d(ta[i], sa[i]).shape[0]/len(ta[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.014776789265974382"
      ]
     },
     "execution_count": 6103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(np.array(isec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
